{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1puNs4ugRT08sC-oYGGqWJ1Iv3VidYiPD","timestamp":1703117860209}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import string"],"metadata":{"id":"dQUNqFJynq5m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def standardize(text):\n"," text = text.lower()\n"," return \"\".join(char for char in text if char not in string.punctuation)\n","\n","def tokenize(text):\n"," text = standardize(text)\n"," return text.split()"],"metadata":{"id":"RaMUt7SKnjVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Lu-dJu3nWQE","executionInfo":{"status":"ok","timestamp":1703053151280,"user_tz":-210,"elapsed":6,"user":{"displayName":"Amin Heydari","userId":"16191566824280308904"}},"outputId":"3ba63fb3-aede-4c65-a079-f42317b209e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'i': 0, 'write': 1, 'erase': 2, 'rewrite': 3}"]},"metadata":{},"execution_count":8}],"source":["dataset = [\"I write, erase, rewrite\"]\n","\n","vocabulary = {}\n","for text in dataset:\n"," text = standardize(text)\n"," tokens = tokenize(text)\n"," for token in tokens:\n","  if token not in vocabulary:\n","   vocabulary[token] = len(vocabulary)\n","\n","vocabulary"]},{"cell_type":"code","source":["import string\n","class Vectorizer:\n"," def standardize(self, text):\n","  text = text.lower()\n","  return \"\".join(char for char in text if char not in string.punctuation)\n","\n"," def tokenize(self, text):\n","  text = self.standardize(text)\n","  return text.split()\n","\n"," def make_vocabulary(self, dataset):\n","  self.vocabulary = {\"\": 0, \"[UNK]\": 1}\n","  for text in dataset:\n","   text = self.standardize(text)\n","   tokens = self.tokenize(text)\n","   for token in tokens:\n","    if token not in self.vocabulary:\n","     self.vocabulary[token] = len(self.vocabulary)\n","\n","  self.inverse_vocabulary = dict((v, k) for k, v in self.vocabulary.items())\n","\n"," def encode(self, text):\n","  text = self.standardize(text)\n","  tokens = self.tokenize(text)\n","  return [self.vocabulary.get(token, 1) for token in tokens]\n","\n"," def decode(self, int_sequence):\n","  return \" \".join(self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence)\n","\n","vectorizer = Vectorizer()\n","dataset = [\n","\"I write, erase, rewrite\",\n","\"Erase again, and then\",\n","\"A poppy blooms.\",\n","]\n","vectorizer.make_vocabulary(dataset)"],"metadata":{"id":"ixh3HOe1oGFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = vectorizer.encode(test_sentence)\n","print(encoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hWGi2RjvobT8","executionInfo":{"status":"ok","timestamp":1703053151280,"user_tz":-210,"elapsed":4,"user":{"displayName":"Amin Heydari","userId":"16191566824280308904"}},"outputId":"22bc907b-36df-4c3e-8ee4-17920cc9e114"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 3, 5, 7, 1, 5, 6]\n"]}]},{"cell_type":"code","source":["decoded_sentence = vectorizer.decode(encoded_sentence)\n","print(decoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvmWbrHXodRl","executionInfo":{"status":"ok","timestamp":1703053151280,"user_tz":-210,"elapsed":3,"user":{"displayName":"Amin Heydari","userId":"16191566824280308904"}},"outputId":"eea1fcf3-dc75-467e-d53e-04a0ab711f7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["i write rewrite and [UNK] rewrite again\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.layers import TextVectorization\n","\n","text_vectorization = TextVectorization(\n"," output_mode=\"int\",\n",")"],"metadata":{"id":"cRZtehIdos8-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import tensorflow as tf\n","\n","def custom_standardization_fn(string_tensor):\n"," lowercase_string = tf.strings.lower(string_tensor)\n"," return tf.strings.regex_replace(lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n","\n","def custom_split_fn(string_tensor):\n"," return tf.strings.split(string_tensor)\n","\n","\n","text_vectorization = TextVectorization(\n"," output_mode=\"int\",\n"," standardize=custom_standardization_fn,\n"," split=custom_split_fn,\n",")"],"metadata":{"id":"QhnPkmi9oilT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = [\n","\"I write, erase, rewrite\",\n","\"Erase again, and then\",\n","\"A poppy blooms.\",\n","]\n","\n","text_vectorization.adapt(dataset)"],"metadata":{"id":"7wnNwniQoy3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_vectorization.get_vocabulary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hf6-0eqPo1hQ","executionInfo":{"status":"ok","timestamp":1703032480158,"user_tz":-210,"elapsed":5,"user":{"displayName":"Amin Heydari","userId":"16191566824280308904"}},"outputId":"d9606ead-515e-4bbd-f503-334d62036b35"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['', '[UNK]']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["vocabulary = text_vectorization.get_vocabulary()\n","test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = text_vectorization(test_sentence)\n","print(encoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2n5Z3NgNo5u0","executionInfo":{"status":"ok","timestamp":1703032481023,"user_tz":-210,"elapsed":5,"user":{"displayName":"Amin Heydari","userId":"16191566824280308904"}},"outputId":"d618ac53-55de-4696-f23e-23bb0d9eb3ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"]}]},{"cell_type":"code","source":["inverse_vocab = dict(enumerate(vocabulary))\n","decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n","print(decoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRL4zhBXo9xi","executionInfo":{"status":"ok","timestamp":1703032481023,"user_tz":-210,"elapsed":4,"user":{"displayName":"Amin Heydari","userId":"16191566824280308904"}},"outputId":"e88f0d63-6815-4126-92aa-c79e8e1b3883"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["i write rewrite and [UNK] rewrite again\n"]}]}]}