{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1wFz6hPi9E0tC9ZisoYzSciMrlhLu2Sou","timestamp":1703120681511},{"file_id":"1meWFpfqzNPP0qcbvJ0AwkI36Pt6jWonN","timestamp":1703117852021}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbU9foocpgtA","executionInfo":{"status":"ok","timestamp":1703135982726,"user_tz":-210,"elapsed":32362,"user":{"displayName":"Fariba Tavakoli","userId":"13065490785621305557"}},"outputId":"0341fbbb-163e-4c98-e9ae-95f27dbedcd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  4792k      0  0:00:17  0:00:17 --:--:-- 4710k\n"]}],"source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz"]},{"cell_type":"code","source":["!rm -r aclImdb/train/unsup\n","!cat aclImdb/train/pos/4077_10.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzM4wNRlpswH","executionInfo":{"status":"ok","timestamp":1703136018597,"user_tz":-210,"elapsed":2266,"user":{"displayName":"Fariba Tavakoli","userId":"13065490785621305557"}},"outputId":"bd6b6874-da13-4b3d-f61c-878437ed737c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"]}]},{"cell_type":"code","source":["import os, pathlib, shutil, random\n","\n","base_dir = pathlib.Path(\"aclImdb\")\n","val_dir = base_dir / \"val\"\n","train_dir = base_dir / \"train\"\n","for category in (\"neg\", \"pos\"):\n"," os.makedirs(val_dir / category)\n"," files = os.listdir(train_dir / category)\n"," random.Random(1337).shuffle(files)\n"," num_val_samples = int(0.2 * len(files))\n"," val_files = files[-num_val_samples:]\n"," for fname in val_files:\n","  shutil.move(train_dir / category / fname, val_dir / category / fname)"],"metadata":{"id":"GTSaz6QxpxYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","batch_size = 32\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","\"aclImdb/train\", batch_size=batch_size\n",")\n","val_ds = keras.utils.text_dataset_from_directory(\n","\"aclImdb/val\", batch_size=batch_size\n",")\n","test_ds = keras.utils.text_dataset_from_directory(\n","\"aclImdb/test\", batch_size=batch_size\n",")"],"metadata":{"id":"LFOcslH8p530","executionInfo":{"status":"ok","timestamp":1703136043501,"user_tz":-210,"elapsed":7294,"user":{"displayName":"Fariba Tavakoli","userId":"13065490785621305557"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"82441404-940b-4567-827f-13ceffb5a7d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["for inputs, targets in train_ds:\n","  print(\"inputs.shape:\", inputs.shape)\n","  print(\"inputs.dtype:\", inputs.dtype)\n","  print(\"targets.shape:\", targets.shape)\n","  print(\"targets.dtype:\", targets.dtype)\n","  print(\"inputs[0]:\", inputs[0])\n","  print(\"targets[0]:\", targets[0])\n","  break"],"metadata":{"id":"wqFaiPTDp-wK","executionInfo":{"status":"ok","timestamp":1703136047196,"user_tz":-210,"elapsed":436,"user":{"displayName":"Fariba Tavakoli","userId":"13065490785621305557"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"93aa8f6a-dcdf-4d0e-ae01-c96b140cc332"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs.shape: (32,)\n","inputs.dtype: <dtype: 'string'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor(b'George Lopez never caught my interest in his stand up comedy and he still doesn\\'t. But this show is a work of art. It\\'s not ever show where the jokes keep you laughing every time you remember it (and jokes that re memorable at that). This show just has an upbeat look to it and the characters range from an old, short drunk to an dyslexic teenager. I don\\'t know who writes this show but that person does a great job. If they had just continued the show I\\'m sure that it would get a positive response from the critics of this great country. If you are looking for a good, traditional comedy, then George Lopez is the show for you! The one bad thing is the title. George Lopez? Really? Imagine the Fresh Prince of Bel-Air being \"Will Smith\". C\\'mon man! But otherwise, this show is genius! 10/10', shape=(), dtype=string)\n","targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.layers import TextVectorization\n","\n","text_vectorization = TextVectorization(\n"," output_mode=\"int\",\n",")"],"metadata":{"id":"cRZtehIdos8-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import string\n","import tensorflow as tf\n","\n","def custom_standardization_fn(string_tensor):\n"," lowercase_string = tf.strings.lower(string_tensor)\n"," return tf.strings.regex_replace(\n"," lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n","\n","def custom_split_fn(string_tensor):\n"," return tf.strings.split(string_tensor)\n","\n","\n","text_vectorization = TextVectorization(\n"," output_mode=\"int\",\n"," standardize=custom_standardization_fn,\n"," split=custom_split_fn,\n",")"],"metadata":{"id":"QhnPkmi9oilT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = [\n","\"I write, erase, rewrite\",\n","\"Erase again, and then\",\n","\"A poppy blooms.\",\n","]\n","\n","text_vectorization.adapt(dataset)"],"metadata":{"id":"7wnNwniQoy3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_vectorization.get_vocabulary()"],"metadata":{"id":"Hf6-0eqPo1hQ","executionInfo":{"status":"ok","timestamp":1703136910745,"user_tz":-210,"elapsed":386,"user":{"displayName":"Fariba Tavakoli","userId":"13065490785621305557"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"50c40d61-cafe-48ba-aa17-a46fca2319e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '[UNK]',\n"," 'erase',\n"," 'write',\n"," 'then',\n"," 'rewrite',\n"," 'poppy',\n"," 'i',\n"," 'blooms',\n"," 'and',\n"," 'again',\n"," 'a']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["vocabulary = text_vectorization.get_vocabulary()\n","test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = text_vectorization(test_sentence)\n","print(encoded_sentence)"],"metadata":{"id":"2n5Z3NgNo5u0","executionInfo":{"status":"ok","timestamp":1703136954765,"user_tz":-210,"elapsed":366,"user":{"displayName":"Fariba Tavakoli","userId":"13065490785621305557"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"34035501-5369-4763-d718-f9404a723574"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"]}]},{"cell_type":"code","source":["inverse_vocab = dict(enumerate(vocabulary))\n","decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n","print(decoded_sentence)"],"metadata":{"id":"mRL4zhBXo9xi","executionInfo":{"status":"ok","timestamp":1703136975484,"user_tz":-210,"elapsed":357,"user":{"displayName":"Fariba Tavakoli","userId":"13065490785621305557"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6aa11e02-94bd-4e9b-f6c5-b0852a27637d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["i write rewrite and [UNK] rewrite again\n"]}]},{"cell_type":"code","source":["text_vectorization = TextVectorization(\n","max_tokens=20000,\n","output_mode=\"multi_hot\",\n",")\n","\n","text_only_train_ds = train_ds.map(lambda x, y: x)\n","text_vectorization.adapt(text_only_train_ds)\n","\n","binary_1gram_train_ds = train_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","\n","binary_1gram_val_ds = val_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","\n","binary_1gram_test_ds = test_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)"],"metadata":{"id":"u3ilEH-Uqdn-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for inputs, targets in binary_1gram_train_ds:\n"," print(\"inputs.shape:\", inputs.shape)\n"," print(\"inputs.dtype:\", inputs.dtype)\n"," print(\"targets.shape:\", targets.shape)\n"," print(\"targets.dtype:\", targets.dtype)\n"," print(\"inputs[0]:\", inputs[0])\n"," print(\"targets[0]:\", targets[0])\n"," break"],"metadata":{"id":"njWBifkEqjB8","executionInfo":{"status":"ok","timestamp":1703137434142,"user_tz":-210,"elapsed":405,"user":{"displayName":"Fariba Tavakoli","userId":"13065490785621305557"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"26dfeb68-af3e-4952-bc21-8d3acfa5afe0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs.shape: (32, 20000)\n","inputs.dtype: <dtype: 'float32'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n","targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"]}]},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","def get_model(max_tokens=20000, hidden_dim=16):\n"," inputs = keras.Input(shape=(max_tokens,))\n"," x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n"," x = layers.Dropout(0.5)(x)\n"," outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n"," model = keras.Model(inputs, outputs)\n"," model.compile(optimizer=\"rmsprop\",\n","               loss=\"binary_crossentropy\",\n","               metrics=[\"accuracy\"]\n","               )\n"," return model"],"metadata":{"id":"viUXHobUqnVK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = get_model()\n","model.summary()\n","\n","callbacks = [\n","keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n","save_best_only=True)\n","]\n","\n","model.fit(binary_1gram_train_ds.cache(),\n","          validation_data=binary_1gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks\n","          )\n","\n","model = keras.models.load_model(\"binary_1gram.keras\")\n","print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"],"metadata":{"id":"cAB8RHJaqwEg","executionInfo":{"status":"error","timestamp":1703138185127,"user_tz":-210,"elapsed":47168,"user":{"displayName":"Fariba Tavakoli","userId":"13065490785621305557"}},"colab":{"base_uri":"https://localhost:8080/","height":986},"outputId":"710104fe-7ab7-4a2c-96f8-1eab4119fccd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense (Dense)               (None, 16)                320016    \n","                                                                 \n"," dropout (Dropout)           (None, 16)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320033 (1.22 MB)\n","Trainable params: 320033 (1.22 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 10s 14ms/step - loss: 0.4020 - accuracy: 0.8309 - val_loss: 0.3083 - val_accuracy: 0.8822\n","Epoch 2/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.2753 - accuracy: 0.8986 - val_loss: 0.3035 - val_accuracy: 0.8854\n","Epoch 3/10\n","625/625 [==============================] - 4s 7ms/step - loss: 0.2433 - accuracy: 0.9143 - val_loss: 0.3221 - val_accuracy: 0.8856\n","Epoch 4/10\n","625/625 [==============================] - 5s 9ms/step - loss: 0.2247 - accuracy: 0.9237 - val_loss: 0.3302 - val_accuracy: 0.8888\n","Epoch 5/10\n","625/625 [==============================] - 4s 6ms/step - loss: 0.2139 - accuracy: 0.9277 - val_loss: 0.3685 - val_accuracy: 0.8816\n","Epoch 6/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.2158 - accuracy: 0.9301 - val_loss: 0.3652 - val_accuracy: 0.8852\n","Epoch 7/10\n","625/625 [==============================] - 4s 6ms/step - loss: 0.2089 - accuracy: 0.9341 - val_loss: 0.3814 - val_accuracy: 0.8834\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-10fcfafb5ac1>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model.fit(binary_1gram_train_ds.cache(),\n\u001b[0m\u001b[1;32m     10\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary_1gram_val_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m         \"\"\"Resets the state of all the metrics in the model.\n\u001b[1;32m   2705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["text_vectorization = TextVectorization(\n","ngrams=2,\n","max_tokens=20000,\n","output_mode=\"multi_hot\",\n",")"],"metadata":{"id":"9yzqocLhq3wP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_vectorization.adapt(text_only_train_ds)\n","\n","binary_2gram_train_ds = train_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","\n","binary_2gram_val_ds = val_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","\n","binary_2gram_test_ds = test_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","\n","\n","model = get_model()\n","model.summary()\n","\n","callbacks = [\n","keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n","save_best_only=True)\n","]\n","\n","model.fit(binary_2gram_train_ds.cache(),\n","validation_data=binary_2gram_val_ds.cache(),\n","epochs=10,\n","callbacks=callbacks)\n","model = keras.models.load_model(\"binary_2gram.keras\")\n","print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"],"metadata":{"id":"5szBBwAArCmU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_vectorization = TextVectorization(\n","ngrams=2,\n","max_tokens=20000,\n","output_mode=\"count\"\n",")"],"metadata":{"id":"vAFdOuAPrKCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_vectorization = TextVectorization(\n","ngrams=2,\n","max_tokens=20000,\n","output_mode=\"tf_idf\",\n",")"],"metadata":{"id":"Ov7gNLhqrNOV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_vectorization.adapt(text_only_train_ds)\n","\n","tfidf_2gram_train_ds = train_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","\n","tfidf_2gram_val_ds = val_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","\n","tfidf_2gram_test_ds = test_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n","save_best_only=True)\n","]\n","\n","model.fit(tfidf_2gram_train_ds.cache(),\n","validation_data=tfidf_2gram_val_ds.cache(),\n","epochs=10,\n","callbacks=callbacks)\n","model = keras.models.load_model(\"tfidf_2gram.keras\")\n","print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"],"metadata":{"id":"ETOXRsY7rO9_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","max_length = 600\n","max_tokens = 20000\n","text_vectorization = layers.TextVectorization(\n","max_tokens=max_tokens,\n","output_mode=\"int\",\n","output_sequence_length=max_length,\n",")\n","text_vectorization.adapt(text_only_train_ds)\n","int_train_ds = train_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","int_val_ds = val_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)\n","int_test_ds = test_ds.map(\n","lambda x, y: (text_vectorization(x), y),\n","num_parallel_calls=4)"],"metadata":{"id":"9A-w-hiGscjW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = tf.one_hot(inputs, depth=max_tokens)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n"," loss=\"binary_crossentropy\",\n"," metrics=[\"accuracy\"])\n","model.summary()\n","callbacks = [\n"," keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n"," save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n"," callbacks=callbacks)\n","model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"],"metadata":{"id":"iZB_Zkxuryyv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n"," loss=\"binary_crossentropy\",\n"," metrics=[\"accuracy\"])\n","model.summary()\n","callbacks = [\n"," keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n"," save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n"," callbacks=callbacks)\n","model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"],"metadata":{"id":"_6Y0GnvItxN7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = layers.Embedding(\n"," input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n"," loss=\"binary_crossentropy\",\n"," metrics=[\"accuracy\"])\n","model.summary()"],"metadata":{"id":"3JKe9QRZt4Dz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callbacks = [\n"," keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n"," save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,\n"," callbacks=callbacks)\n","model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"],"metadata":{"id":"d35Kp1xxt7ir"},"execution_count":null,"outputs":[]}]}